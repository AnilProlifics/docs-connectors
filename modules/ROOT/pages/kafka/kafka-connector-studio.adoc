= Kafka Studio Configuration - Mule 4
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]

In Anypoint Studio, add Kafka Connector to a Mule project, configure the connection to the Kafka cluster, and configure an input source for the connector. 

To configure a connector in Anypoint Studio:

. Add the connector to a Mule project.
. Configure the connector.
. Configure an input source for the connector.

== Add the Connector in Studio

. In Studio, create a Mule Project.
. In the Mule Palette, click *(X) Search in Exchange*.
. In *Add Modules to Project*, type the name of the connector in the search field.
. Click the connector name in *Available modules*.
. Click *Add*.
. Click *Finish*.

== Add the Connector Using Exchange

. In Studio, create a Mule Project.
. Click the Exchange *(X)* icon in the upper-left of the Studio task bar.
. In Exchange, click *Login* and supply your Anypoint Platform username and password.
. In Exchange, select *All assets* and search for "Kafka".
. Select Kafka Connector and click *Add to project*.
. Follow the prompts to add the connector to the Mule project.

== Configure the Connector

. Drag the connector operation to the Studio canvas.
. To create a global element for the connector, configure these fields:
+
* *Connection*:
** Bootstrap Servers +
Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the `bootstrap.servers` value you must provide to Kafka clients (producer or consumer).
** Additional properties +
Add any additional properties that you need for your connection (and that Kafka supports) as key-value pairs.
+
image::kafka/kafka-basic-studio-config.png[]
+
* For *SSL*, configure the *Basic* fields as well as the following:
** Key Store Type +
Optionally specify the file format of the keystore file. The default value is `JKS`.
** Key Store Password +
The store password for the keystore file. This is optional and needed only if the *Key Store Location* is configured.
** Key Store Location +
The location of the keystore file. This is optional and can be used for two-way authentication for the connector.
** Trust Store Type +
The file format of the truststore file.
** Trust Store Password +
The password for the truststore file.
** Trust Store Location +
The location of the truststore file.
+
image::kafka/kafka-ssl-studio-config.png[]
+
//// 
* For *Kerberos*, configure the *Basic* fields as well as the following:
** All the parameters from the basic configuration.
** Principal +
The Kerberos principal to which Kerberos can assign tickets.
** Keytab +
Path to the keytab file associated with `principal`.
** Service Name +
The Kerberos principal name under which the Kafka broker runs.
** Additional JAAS Properties +
Additional properties as key-value pairs that you set in `sasl.jaas.config` and that you usually include in the JAAS configuration file.
+
image::kafka/kafka-kerberos-studio-config.png[]
+
.. For *Kerberos SSL*, configure the following:
** All the parameters from the basic configuration.
** All the parameters from the SSL configuration.
** All the parameters from the Kerberos configuration.
+
image::kafka/kafka-kerberos-ssl-studio-config.png[]
+
////
. Configure the fields for the operation that you dragged to the canvas.
.. Configure the *Commit* operation fields:
** Bean Reference (Optional) +
The URLs that the consumer can use to connect to the Kafka cluster.
** Group ID +
Default group ID for all the Kafka consumers that use this configuration.
** Offsets (Optional) +
List of offsets for configuring partitions. For each element in the list, specify the partition index and offset.
** Topic Subscription Patterns (Optional) +
The list of subscription regular expressions to subscribe to. Topics are automatically rebalanced according to the number of consumers of the topic.
** Assignments (Optional) +
The list of topic-partition pairs to assign. Note that consumers are not automatically rebalanced.
+
image::kafka/kafka-consumer-studio-config.png[]
+
** Default acknowledgment mode +
Declares the type of supported acknowledgment mode
** Default poll timeout +
The amount of time to block
** Default poll timeout time unit +
The time unit for the poll timeout. Used with poll timeout to define the total timeout for the polling.
** Zone ID (Optional) +
Converts the provided timestamps into `ZonedLocalDateTimes` in the results. Default value is the one provided by the system.
+
image::kafka/kafka-consumer-studio-config-general.png[]
+
.. Configure the *Consume* operation fields:
** Bean Reference (Optional) +
The URLs that the consumer can use to connect to the Kafka cluster
** Group ID +
Default group ID for all the Kafka consumers that use this configuration
** Offsets (Optional) +
List of offsets for configuring partitions. For each element in the list, specify the partition index and offset.
** Topic Subscription Patterns (Optional) +
The list of subscription regular expressions to subscribe to. Topics are automatically rebalanced according to the number of consumers of the topic.
** Assignments (Optional) + 
The list of topic-partition pairs to assign. Note that the consumers are not automatically rebalanced.
+
image::kafka/kafka-consumer-studio-config.png[]
+
** Default acknowledgment mode +
Declares the type of acknowledgment mode supported
** Default poll timeout + 
The amount of time to block
** Default poll timeout time unit +
The time unit for the polling timeout. This combines with pollTimeout to define to total timeout for the polling.
** Zone ID (Optional) +
Zone ID is used to convert the provided timestamps into `ZonedLocalDateTimes` in the results. The default value is the one provided by the system.
+
image::kafka/kafka-producer-studio-config-general.png[]
+
.. Configure the *Describe* operation fields:
** Bean Reference (Optional) +
The URLs that the consumer can use to connect to the Kafka cluster
** Group ID +
Default group ID for all the Kafka consumers that use this configuration
** Offsets (Optional) +
List of offsets for configuring partitions. For each element in the list, specify the partition index and offset.
** Topic Subscription Patterns (Optional) +
The list of subscription regular expressions to subscribe to. Topics are automatically rebalanced according to the number of consumers of the topic.
** Assignments (Optional) +
The list of topic-partition pairs to assign. Note that there will be no automatic rebalance of the consumers.
+
image::kafka/kafka-consumer-studio-config.png[]
+
** Default acknowledgment mode +
Declares the type of acknowledgment mode supported
** Default poll timeout +
The amount of time to block. Defines the total timeout for polling.
** Default poll timeout time unit +
The time unit for the polling timeout. Used with poll timeout to define the total timeout for the polling.
** Zone ID (Optional) +
Zone ID is used to convert the provided time stamps into `ZonedLocalDateTimes` in the results. Default value is the one provided by the system.
+
image::kafka/kafka-consumer-studio-config-general.png[]
+
.. Configure the *Publish* operation fields:
** Bean Reference (Optional) +
The URLs that the consumer can use to connect to the Kafka cluster
+
image::kafka/kafka-consumer-studio-config-publish.png[]
+
** Default topic +
A default topic name
+
image::kafka/kafka-consumer-studio-config-publish-general.png[]
+
.. Configure the *Seek* operation fields:
** Bean Reference (Optional) +
The URLs that the consumer can use to connect to the Kafka cluster
** Group ID +
Default group ID for all the Kafka consumers that use this configuration
** Offsets (Optional) +
List of offsets for configuring partitions. For each element in the list, specify the partition index and offset.
** Topic Subscription Patterns (Optional) +
The list of subscription regular expressions to subscribe to. Topics are automatically rebalanced according to the number of consumers of the topic.
** Assignments (Optional) +
The list of topic-partition pairs to assign. Note that there will be no automatic rebalance of the consumers.
+
image::kafka/kafka-consumer-studio-config.png[]
+
** Default acknowledgment mode +
Declares the type of acknowledgment mode supported
** Default poll timeout +
The amount of time to block. Specifies the total timeout for the polling.
** Default poll timeout time unit +
The time unit for the polling timeout. This combines with poll timeout to define the total timeout for the polling.
** Zone ID (Optional) +
Zone ID is used to convert the provided time stamps into `ZonedLocalDateTimes` in the results. Default value is the one provided by the system.
+
image::kafka/kafka-consumer-studio-config-general.png[]


== Configure an Input Source

Configure an input source for the connector, such as the *Message Consumer* operation:

[%header,cols="30s,70a"]
|===
| Name | Description
| Configuration |The name of the configuration to use
| Topic |Name of the topic from which to consume messages
| Partition Offsets a| List of offsets (array of offsets) representing the partitions offsets configuration. For each element in the list you must specify a partition index and offset.
| Primary Node Only |Whether to execute this source on only the primary node when running in a cluster.
| Streaming Strategy a| * repeatable-in-memory-stream
* repeatable-file-store-stream
* non-repeatable-stream

Configure to use repeatable streams.
| Redelivery Policy a| Defines a policy for processing the redelivery of the same message
| Reconnection Strategy a| * reconnect
* reconnect-forever +
A retry strategy in case of connectivity errors
|===


The *Batch Message Consumer* operation can also be used as an input source in Kafka Connector:

[%header,cols="30s,70a"]
|===
| Name | Description
| Configuration |The name of the configuration to use.
| Poll timeout |The amount of time to block. 
| Poll timeout time unit |  The time unit for the polling timeout. This combines with poll timeout to define the total timeout for the polling.
| Acknowledgment mode | Declares the supported acknowledgment mode type
| Amount of parallel consumers | Declares how many consumers to use in parallel
| Primary Node Only |Whether this source should be executed only on the primary node when running in a cluster
| Streaming Strategy a| * repeatable-in-memory-stream
* repeatable-file-store-stream
* non-repeatable-stream

Configure to use repeatable streams.
| Redelivery Policy a| Defines a policy for processing the redelivery of the same message.
| Reconnection Strategy a| * reconnect
* reconnect-forever +  
A retry strategy in case of connectivity errors

|===

== See Also

https://help.mulesoft.com[MuleSoft Help Center]
