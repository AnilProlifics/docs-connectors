= Kafka Studio Configuration - Mule 4
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]
:imagesdir: ../../assets/images/

To configure a connector in Anypoint Studio:

. Install the connector.
. Configure the connector.
. Configure an input source for the connector.

== Install the Connector in Studio

. In Studio, create a Mule Project.
. In the Mule Palette, click *(X) Search in Exchange*.
. In *Add Modules to Project*, type the name of the connector in the search field.
. Click the connector name in *Available modules*.
. Click *Add*.
. Click *Finish*.

== Install the Connector in Exchange

. In Studio, create a Mule Project.
. Click the Exchange *(X)* icon in the Studio task bar.
. In Exchange, click *Login* and supply your Anypoint Platform username and password.
. In Exchange, select *All assets* and search for "Kafka".
. Select Kafka, click *Add to project*.
. Follow the prompts to install the connector.

== Configure the Connector

. Drag the connector operation to the Studio Canvas.
. To create a global element for the connector, set these fields:
+
.. Basic:
** Bootstrap Servers - Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the `bootstrap.servers` value you must provide to Kafka clients (producer or consumer).
** Additional properties - Additional properties as key-value pairs that you need for your connection. Here you can put whatever property Kafka supports.
+
image::kafka/kafka-basic-studio-config.png[]
+
.. SSL:
** All the parameters from Basic configuration.
** Key Store Type - The file format of the key store file. This is optional and the default value is `JKS`.
** Key Store Password - The store password for the key store file. This is optional and only needed if *Key Store Location* is configured.
** Key Store Location - The location of the key store file. This is optional and can be used for two-way authentication for connector.
** Trust Store Type - The file format of the trust store file.
** Trust Store Password - The password for the trust store file.
** Trust Store Location - The location of the trust store file.
+
image::kafka/kafka-ssl-studio-config.png[]
+
.. Kerberos:
** All the parameters from the Basic configuration.
** Principal - Kerberos principal
** Keytab - Path to keytab file associated with the `principal`.
** Service Name - The Kerberos principal name that the Kafka broker runs as.
** Additional JAAS Properties - Additional properties as key-value pairs that you set in `sasl.jaas.config` and that you usually include in JAAS configuration file.
+
image::kafka/kafka-kerberos-studio-config.png[]
+
.. Kerberos SSL:
** All the parameters from the Basic configuration.
** All the parameters from the SSL configuration.
** All the parameters from the Kerberos configuration.
+
image::kafka/kafka-kerberos-ssl-studio-config.png[]
+
. Based on the operation what you dragged to the canvas, configure the following fields:
.. Consumer trigger:
** Topic - The name of the Kafka topic where to consume messages.
** Partition offsets (Optional) - list of offsets for configuring partitions. For each element in the list, specify the partition index and offset.
+
image::kafka/kafka-consumer-studio-config.png[]
+
.. Producer operation:
** Topic - Topic to send the message to.
** Key - Key belonging to the message that is going to be sent.
** Message - Message to be sent.
+
image::kafka/kafka-producer-studio-config.png[]

== Configure an Input Source

Configure an input source for the connector such as a connector operation, using an *HTTP Listener*, or *Scheduler*.

The *Message Consumer* operation can be used as an input source in the Kafka connector.

*Message Consumer* fields:

[%header,cols="30s,70a"]
|===
| Name | Description
| Configuration |The name of the configuration to use.
| Topic |Name of the topic to consume messages from.
| Partition Offsets a| Array of Offset - List of Offset representing partitions offsets configuration. For each element in the list you have to specify partition index and offset.
| Primary Node Only |Whether this source should only be executed on the primary node when running in Cluster. 
| Streaming Strategy a| * repeatable-in-memory-stream
* repeatable-file-store-stream
* non-repeatable-stream 

Configure to use repeatable streams. 
| Redelivery Policy a| RedeliveryPolicy -  Defines a policy for processing the redelivery of the same message. 
| Reconnection Strategy a| * reconnect
* reconnect-forever -  A retry strategy in case of connectivity errors.
|===

== See Also

https://help.mulesoft.com[MuleSoft Help Center]
