= Kafka Design Center Configuration - Mule 4
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]
:imagesdir: ../../assets/images/

Design Center enables you to create apps visually. To use Design Center, work with your Anypoint Platform administrator to ensure that you have a xref:access-management::environments.adoc#to-create-a-new-environment[Design environment]. For more information, see the xref:design-center::fd-tour.adoc[Flow Designer Tour]. Design Center automatically saves changes you make in a session.

To create an app in Design Center:

* Configure the input source (trigger) for your app.
* Add the connector as a component to process the input for the app.

For information on field values, see the xref:kafka/kafka-connector-reference.adoc[Kafka Connector Reference].

== Configure the Trigger

. In Design Center, click *Create*.
. Click *Create new application*.
. Specify a value for *Project name*.
. Exit from *Let's get started* by clicking *Go straight to canvas*.
. Click the name of the trigger card.
. If you are using the Kafka connector as an input source trigger, search for the connector; otherwise, search for HTTP or Scheduler.
. Complete the fields with the values you want to configure for your trigger.

The Kafka connector provides the *Message Consumer* operation as an input source.

To configure the *Message Consumer* operation, set the field values:

[%header,cols="30s,70a"]
|===
| Name | Description
| Topic |  Name of the topic to consume messages from.
| Connection |

* <<basiccon>>
* <<sslcon>>
* <<kerbcon>>
* <<kerbssl>>
| Partition Offsets |  List of Offset representing partitions offsets configuration. For each element in the list you have to specify partition index and offset. 
|Primary Node Only | Whether this source should only be executed on the primary node when running in a cluster.
|===

To configure a consumer (trigger) for all configurations, set:

* Consumer Partitions - The number of partitions to use for the consumer.
* Group Id - A unique string that identifies the consumer group this consumer belongs to.

[[basiccon]]
=== Kafka Basic Consumer Connection

[%header,cols="30s,70a"]
|===
| Name | Description
|Bootstap Servers | Comma-separated host-port pairs used for establishing the initial connection to the Kafka cluster. This is the same as the bootstrap.servers value you must provide to Kafka clients (producer/consumer).
| Additional Properties | Additional properties as key and value that you need for your connection. Here you can put whatever property Kafka supports.
|===

image::kafka/kafka-basic-dc-config.png[]

[[sslcon]]
=== Kafka SSL Consumer Connection

Uses all the parameters from <<basiccon>>.

[%header,cols="30s,70a"]
|===
| Name | Description
| Key Store Type | The file format of the key store file. This is optional and default value is "JKS".
| Key Store Password | The store password for the key store file. This is optional and only needed if "keyStoreLocation" is configured.
| Key Store Location | The location of the key store file. This is optional and can be used for two-way authentication for connector.
| Trust Store Type | The file format of the trust store file.
| Trust Store Password | The password for the trust store file.
| Trust Store Location | The location of the trust store file.
|===

image::kafka/kafka-ssl-dc-config.png[]

[[kerbcon]]
=== Kafka Kerberos Consumer Connection

Uses all the parameters from <<basiccon>>.

[%header,cols="30s,70a"]
|===
| Name | Description
| Principal | Kerberos principal
| Keytab | Path to keytab file associated with "principal".
| Service Name | The Kerberos principal name that Kafka Broker runs as.
| Additional JAAS Properties | Additional properties as key->value that you need to set on "sasl.jaas.config" and that you usually include in JAAS configuration file.
|===

image::kafka/kafka-kerberos-dc-config.png[]

[[kerbssl]]
=== Kafka Kerberos SSL Consumer Connection

Uses all the parameters from these configurations:

* <<basiccon>>
* <<sslcon>>
* <<kerbcon>>

image::kafka/kafka-kerberos-ssl-dc-config.png[]

=== Add a Component

. Click “+” next to the trigger card.
. In *Select a component*, search for the connector name.
. Select the Kafka connector as the component.
+
Configure these fields:
+
. Consumer trigger:
** Topic - name of Kafka topic to consume messages from.
** Partition offsets(Optional) - list of Offset representing partitions offsets configuration. For each element in the list you have to specify partition index and offset.
+
image::kafka/kafka-consumer-dc-config.png[]
+
. Producer operation:
** Topic - Topic to send the message to.
** Key - Key belonging to the message that is going to be sent.
** Message - Message to be sent.
+
image::kafka/kafka-producer-dc-config.png[]

== Next

Now that you have completed configuring Design Center, see the xref:kafka/kafka-connector-config-topics.adoc[Additional Configuration Information] topic for more configuration ideas.

== See Also

* https://forums.mulesoft.com[MuleSoft Forum]
