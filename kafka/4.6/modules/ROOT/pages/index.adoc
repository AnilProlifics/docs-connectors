= Apache Kafka Connector 4.6 - Mule 4
:page-aliases: connectors::kafka/kafka-connector.adoc



Anypoint Connector for Apache Kafka (Apache Kafka Connector) enables you to interact with the Apache Kafka messaging system and achieve seamless integration between your Mule app and a Kafka cluster, using Mule runtime engine (Mule).

For compatibility information, see the Apache Kafka Connector Release Notes.

== Before You Begin

Before creating an app, you must:

* Have access to the Apache Kafka target resource and Anypoint Platform
* Understand how to create a Mule app using Anypoint Studio
* Have access to Apache Kafka to get values for the fields that appear in Studio

== Use Cases

Apache Kafka is a multipurpose application. Integration with Apache Kafka relies on the applications that are typically used with it.

Example use cases include:

* An integration application that ensures that patients in a hospital receive the care they need in a timely manner +
An example of this is a hospital server that processes emergency requests for patient admissions. The requests are ordered by priority determined by specified criteria, such as how critical the patient's condition is and the staff that is available to treat the patient. In this scenario, an application processes Apache Kafka messages in the order that they are received, relying on the order and idempotency of the messages sent through the queue.
* An application that is time-sensitive +
An example is a newsroom that uses the Apache Kafka system to deliver the latest news. To retrieve the latest news, reading from the Apache Kafka queue sometimes requires reading from the end of the queue first.
* Multiple applications that rely on the information provided by Apache Kafka +
For example, a department store uses a website activity tracker to improve the online shopping experience. The data that is gathered is sent to multiple departments for various computations. Each department reviews the information that's received to stay informed about what the customer is looking for and then provides recommendations accordingly.

=== Publish-to Use Cases

With Kafka Connector, applications can publish binary messages to the Kafka server. Some examples of use cases include:

* A user publishing binary data to the Kafka server and the underlying topic of their choice.
* An integration specialist working with large volumes of data who wants to set the batch size of the data to publish to Kafka.
** To optimize for performance, companies can batch messages to send. Kafka stores the message until the batch size is reached and completes the send at that time.
* A user focusing on optimal performance who wants to configure the message size that they send.
** Kafka is not intended to process and handle large messages. Messages are typically in the 1 MB range and users set the size to avoid performance degradation. In the case of an error, the message is rejected.
* A user ensuring successful data transmission and wants to block further commits on a configurable level of acknowledgment for the messages published to the Kafka server.
** Acknowledgments allow users to ensure that the message is sent prior to publishing more messages. This is specifically useful in time-ordered or event-ordered messages, such as logs or patient drug administration orders. Ensuring that messages are sent in order helps the downstream application process the messages in the right order.
* A user configuring how data is serialized during a publish.
* A user securing messages sent during Mutual TLS.

The following lists the acceptance criteria for publishing:

* Publish a message to a Kafka topic.
* Configure the batch size and size of the message.
* Obtain an acknowledgment once publishing is complete at the configured level.
* Send the message securely via Mutual TLS.
* Configure the serialization type.

=== Subscribe-from Use Cases

With Kafka Connector, applications can obtain messages from Kafka for further consumption downstream. Some examples of use cases include:

Reading from Kafka:

* A user subscribing to the Kafka server and the underlying group of their choice to read and consume messages for downstream processing.
* A user subscribing to a specific Kafka partition to process messages.
** Users with a high availability microservice don't want to rely on Kafka's rebalancing in the event of a failure.
** If a user has a local state associated with their partition, the user wants to process only that partition.
* Users configure the value of their offset to a set value or the beginning or the end of the topic assigned to them.
** A user has a local store and wants to use that information to start processing their records.
** A user has time-sensitive records and wants to skip to the end if the application must be up-to-date or skip to the beginning if it is a new application processing the records.
* A user, on restart, wanting to read the offset value from an alternate storage system.
** A user has a local store with the offset information and wants to read the value from their local storage.
* Users with varying downstream processing intervals want to set the interval for which to block the receipt of messages.

Processing the messages:

* A user who sometimes runs into their downstream application crashing and wants to ensure there is no data loss. To have more control, they want to manually configure their commits.
* A user who wants to store their commit value in a local store or in the Kafka storage and block until the store is successful.
* A user who wants to store their offset in a local store or in the Kafka storage asynchronously.
* A user who has multiple applications reading from the same group ID and wants to use Kafka's in-built capability of load-balancing.
* A user who wants to configure the number of records they process in a single call.

The following lists the acceptance criteria for subscribing:

* Read a message from Kafka from a specific partition or topic.
* Read a message from Kafka after obtaining the offset from a local store.
* Read a message from the beginning of the queue, the end of the queue, and a pre-specified offset.
* Ensure performance when there is one consumer per thread. Multiple consumers exist in a single group. 

== Audience

* Starting user
+
To create a Mule app, see xref:kafka-connector-studio.adoc[Apache Kafka Studio Configuration].
+
* Power user
+
Read xref:kafka-connector-xml-maven.adoc[XML and Maven Support]
and xref:kafka-connector-examples.adoc[Examples].

== Next

After you complete the prerequisites, you are ready to create an app with xref:kafka-connector-studio.adoc[Anypoint Studio].

== See Also

* xref:connectors::introduction/introduction-to-anypoint-connectors.adoc[Introduction to Anypoint Connectors]
* xref:connectors::introduction/intro-use-exchange.adoc[Use Exchange to Discover Connectors, Templates, and Examples]
* https://www.mulesoft.com/exchange/com.mulesoft.connectors/mule-kafka-connector/[Apache Kafka Connector]
* https://help.mulesoft.com[MuleSoft Help Center]
